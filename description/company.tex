
\resheading{工作经历}
  \begin{itemize}[leftmargin=*]
         \item
           \ressubsingleline{汇丰科技}{python开发工程师}{2022.07-至今}
           {\small
      \begin{itemize}
      \item 利用python,hive,shell脚本对金融数据进行清洗,利用jenkins,git对代码进行CI/CD管理。
          \item 利用GCP平台对于清洗后的数据进行欺诈可能性的预测。
            \end{itemize}
           }
       \item
           \ressubsingleline{品友互动}{策略算法工程师}{2021.02-2022.06}
           {\small
      \begin{itemize}
      \item 利用Hive，以及Sqoop等工具等数据进行同步以及清洗。
         \item 结合业务理解构建机器学习广汽本田复购模型（特征工程、模型训练），并进行代码管理和优化。
          \item 和思必驰合作参与构建语音语义文本分析模型，主要参与文本的清洗以及后续业务报表构建工作。
           \item 参与gmsm联邦建模工作，利用京东联邦学习平台进行求交优化，主要负责特征工程及模型的调优工作。
            \end{itemize}

             }
  \end{itemize}
\resheading{实习经历}
  \begin{itemize}[leftmargin=*]
     \item
        \ressubsingleline{AIATSS(友邦资讯科技公司）}{测试组数据分析实习}{2020.04-2020.6}
        {\small
      \begin{itemize}
      \item 撰写SQL以及python脚本校核公司内部数据。
        \item 利用jira实时监控工作流程进度，并通过Excel pivot table 绘制组内测试进度报告。
         \item 对测试流程以及ETL开发流程有了更深入的了解。
         
       \end{itemize}
       }
        \item
           \ressubsingleline{TCL工业研究院}{数据挖掘实习}{2020.07-2020.09}
           {\small
      \begin{itemize}
      \item 通过组内讨论，参与制定推荐系统CTR的业务指标，并基于以上指标进行统计分析。
         \item 利用spark负责数据清洗以及异常数据的核验。
          \item 参与组内的论文讨论，并参与大规模特征数据的分类（Random Fourier features SVM)、聚类(minitach kmeans)工作，并参与特征筛选以及特征交叉工作。
           \item 参与组内爬虫代码的日常维护，丰富自身挖掘经验。

            \end{itemize}

             }

  \end{itemize}

\resheading{项目经历}
  \begin{itemize}[leftmargin=*]
    \item
      \ressubsingleline{美国大学生数学建模竞赛}{队长}{2017.02}
      {\small
      \begin{itemize}
      \item 通过层次分析法对城市居住环境影响因素进行统计分析，分析影响因素及其权重。
        \item 通过模糊综合评价与灰度预测法预测各项指标的变化。
        \item 研究城市可持续发展模型，与2位队友共同讨论后，撰写可持续发展数学模型英文论文，描述各项指标变化。
      \end{itemize}
      }
    
    \item
      \ressubsingleline{泰迪杯}{队长}{2018.03 -- 2018.04}
      {\small
      \begin{itemize}
        \item 对电视节目收视率进行量化分析，根据收视分析改进收费节目策略，策略波动显著降低
        \item 研究了协同过滤算法（Item-based,User-based)、SVD、FM 等算法在推荐系统中的应用
        \item 利用 py-spark mlib 对算法进行实现,最终成绩位列top 15\%。
      \end{itemize}
      }


    \item
      \ressubsingleline{Douban web crawler data analysis}{个人项目}{2019.09 – 2019.12}
      {\small
      \begin{itemize}
       \item https://github.com/W55699/doubanbook − web − crawler
       \item 利用正则表达式，并通过创建线程池，多线程爬取豆瓣书籍信息。
       \item 将信息生成 csv 文件，并将信息存入 mysql 数据库。
       \item 利用 pandas读取csv，并做数据可视化分析以及统计分析。
       \item 通过 pca 将数据进行降维，提取关键信息，然后通过 k-means 算法进行聚类分析。 
       \item 根据 pca 降维后的信息,同时结合数据的标记，将数据分为训练集和测试集，并将数据进行二分类，比较各种分类
             方法如SVM,LR，决策树，随机森林算法的优劣。
      \end{itemize}
      }
    \item
      \ressubsingleline{IMDB sentiment analysis}{个人项目}{2020.10 – 2020.12}
      {\small
      \begin{itemize}
      
       \item 利用stop-words对数据集进行清洗，并通过wordcloud进行词云可视化。
       \item 利用python gensim word2vec对文本进行向量化处理。
       \item 训练并调整bi-lstm模型，使模型准确率在测试集中达到85\%。
       \item 利用docker,Tensorflow-serving,streamlit对模型进行部署，实现可视化。
      \end{itemize}
      }


  \end{itemize}


















